name: 'pong_a2c_lstm'


env:
  name: vel.rl.env.classic_atari
  game: 'PongNoFrameskip-v4'


vec_env:
  name: vel.rl.vecenv.shared_mem
  frame_history: 4  # How many stacked frames go into a single observation


model:
  name: vel.rl.models.stochastic_policy_rnn_model

  input_block:
    name: vel.modules.input.image_to_tensor

  backbone:
    name: vel.rl.models.backbone.nature_cnn_rnn
    input_width: 84
    input_height: 84
    input_channels: 4  # The same as frame_history


reinforcer:
  name: vel.rl.reinforcers.on_policy_iteration_reinforcer

  algo:
    name: vel.rl.algo.policy_gradient.a2c
    entropy_coefficient: 0.01
    value_coefficient: 0.5
    max_grad_norm: 0.5
    discount_factor: 0.99

  env_roller:
    name: vel.rl.env_roller.step_env_roller

  number_of_steps: 5 # How many environment steps go into a single batch
  parallel_envs: 16 # How many environments to run in parallel

  shuffle_transitions: off  # Required for RNN policies


optimizer:
  name: vel.optimizers.rmsprop
  lr: 7.0e-4
  alpha: 0.99
  epsilon: 1.0e-3


commands:
  train:
    name: vel.rl.commands.rl_train_command
    total_frames: 1.1e7
    batches_per_epoch: 100

  record:
    name: vel.rl.commands.record_movie_command
    takes: 10
    videoname: 'pong_vid_{:04}.avi'

  evaluate:
    name: vel.rl.commands.evaluate_env_command
    parallel_envs: 16 # How many environments to run in parallel

    takes: 20

  visdom:
    name: vel.commands.vis_store_command
